{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_folder():\n",
    "    roots = ['../data/ratio_h_features', '../data/HOG_features', '../data/all_features']\n",
    "    total_files = 0\n",
    "\n",
    "    for root in roots:\n",
    "        for path in os.listdir(root):\n",
    "            os.remove(os.path.join(root, path))\n",
    "            total_files += 1\n",
    "    \n",
    "    print(\"Removed {} files\".format(total_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 300 files\n",
      "Length of HOG feature: 4\n",
      "Length of hist_all_HOG feature: 5\n",
      "Processed: 100 images\n"
     ]
    }
   ],
   "source": [
    "rootdir = '../data/Raw/Training/'\n",
    "total_img = 0\n",
    "len_HOG_feature = None\n",
    "len_hist_feature = None\n",
    "\n",
    "# Clear feature folders\n",
    "clear_folder()\n",
    "\n",
    "# Initialize parameters for HOG - feature extraction algorithm\n",
    "\n",
    "for path in glob.glob(f'{rootdir}/*/**'):\n",
    "    img = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.resize(gray, (96, 128), interpolation = cv2.INTER_AREA)\n",
    "    gray_arr = np.asarray(gray)\n",
    "\n",
    "    # Ratio hair feature\n",
    "    img_white = np.ones((128, 96), dtype = np.uint8)\n",
    "    count = 0\n",
    "    for i in range(0,128):\n",
    "        for j in range(0,96):\n",
    "            if gray_arr[i][j] <= 51 :\n",
    "                img_white[i][j] = 0\n",
    "                count += 1\n",
    "    ratio_h = [count / (128*96)]\n",
    "\n",
    "    # HOG features\n",
    "    hog_features, hog_image = hog(img_white, orientations = 4, pixels_per_cell=(8, 8),\n",
    "                    cells_per_block=(2, 2), visualize = True)\n",
    "\n",
    "    orient_features = np.zeros((4))\n",
    "    for i in range(len(hog_features)):\n",
    "        orient_features[i%4] += hog_features[i]\n",
    "        \n",
    "    # Concatenate histograms features and HOG features\n",
    "    merged_features = np.concatenate((orient_features, ratio_h))\n",
    "\n",
    "    # Save feature\n",
    "    np.save('../data/ratio_h_features/' + path.split('\\\\')[-1].split('.')[0], ratio_h)\n",
    "    np.save('../data/HOG_features/' + path.split('\\\\')[-1].split('.')[0], orient_features)\n",
    "    np.save('../data/all_features/' + path.split('\\\\')[-1].split('.')[0], merged_features)\n",
    "\n",
    "    # Count number of images\n",
    "    total_img += 1\n",
    "    len_HOG_feature = len(orient_features)\n",
    "\n",
    "### DONE\n",
    "print(\"Length of HOG feature: {}\".format(len_HOG_feature))\n",
    "print(\"Length of hist_all_HOG feature: {}\".format(len_HOG_feature + 1))\n",
    "print(\"Processed: {} images\".format(total_img))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(img, method):\n",
    "\n",
    "    # Convert images to \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.resize(gray, (96, 128), interpolation = cv2.INTER_AREA)\n",
    "    gray_arr = np.asarray(gray)\n",
    "\n",
    "    # Ratio hair feature\n",
    "    img_white = np.ones((128, 96), dtype = np.uint8)\n",
    "    count = 0\n",
    "    for i in range(0,128):\n",
    "        for j in range(0,96):\n",
    "            if gray_arr[i][j] <= 51 :\n",
    "                img_white[i][j] = 0\n",
    "                count += 1\n",
    "    ratio_h = [count / (128*96)]\n",
    "\n",
    "    # HOG features\n",
    "    hog_features, hog_image = hog(img_white, orientations=8, pixels_per_cell=(8, 8),\n",
    "                    cells_per_block=(2, 2), visualize = True)\n",
    "    orient_features = np.zeros((4))\n",
    "    for i in range(len(hog_features)):\n",
    "        orient_features[i%4] += hog_features[i]\n",
    "\n",
    "    # Concatenate histograms features and HOG features\n",
    "    merged_features = np.concatenate((orient_features, ratio_h))\n",
    "\n",
    "    if method == \"Ratio hair\":\n",
    "        return ratio_h\n",
    "    elif method == \"HOG\":\n",
    "        return orient_features\n",
    "    else:\n",
    "        return merged_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(img, method):\n",
    "\n",
    "    #Intialize params\n",
    "    ratio_h_path = \"../data/ratio_h_features/\"\n",
    "    hog_path = \"../data/HOG_features/\"\n",
    "    all_features_path = \"../data/all_features/\"\n",
    "\n",
    "    val = []\n",
    "    idx = []\n",
    "\n",
    "    current_features = get_features(img, method)\n",
    "\n",
    "    if method == \"Ratio hair\":\n",
    "        for path in glob.glob(f'{ratio_h_path}/*'):\n",
    "            ratio_h_tmp = np.load(path)\n",
    "            dist = np.linalg.norm(ratio_h_tmp - current_features)\n",
    "            val.append(dist)\n",
    "            idx.append(path)\n",
    "\n",
    "    elif method == \"HOG\":\n",
    "        for path in glob.glob(f'{hog_path}/*'):\n",
    "            hog_tmp = np.load(path)\n",
    "            dist = np.linalg.norm(hog_tmp - current_features)\n",
    "            val.append(dist)\n",
    "            idx.append(path)\n",
    "\n",
    "    else:\n",
    "        for path in glob.glob(f'{all_features_path}/*'):\n",
    "            all_features_tmp = np.load(path)\n",
    "            dist = np.linalg.norm(all_features_tmp - current_features)\n",
    "            val.append(dist)\n",
    "            idx.append(path)\n",
    "\n",
    "    nearest_img = np.argsort(val)[:3]\n",
    "    res_nu = 0\n",
    "    for img_path in nearest_img:\n",
    "        if 'nu' in idx[img_path]:\n",
    "            res_nu += 1\n",
    "    \n",
    "    return 1 if res_nu > 1 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.9\n",
      "0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "test_path = \"../data/Raw/Test/\"\n",
    "\n",
    "gt = []\n",
    "pred = []\n",
    "\n",
    "for img_path in glob.glob(f'{test_path}/*'):\n",
    "    img = cv2.imread(img_path)\n",
    "    predicted_label = prediction(img, method=\"HOG\")\n",
    "    gt.append(1) if 'nu' in img_path.lower() else gt.append(0)\n",
    "    pred.append(predicted_label)\n",
    "\n",
    "print(precision_score(gt, pred, average='binary'))\n",
    "print(recall_score(gt, pred, average='binary'))\n",
    "print(f1_score(gt, pred, average='binary'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS_ISLAND",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
